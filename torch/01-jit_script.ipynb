{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripting a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.jit.ScriptFunction'>\n",
      "def foo(x: Tensor,\n",
      "    y: Tensor) -> Tensor:\n",
      "  _0 = bool(torch.gt(torch.max(x), torch.max(y)))\n",
      "  if _0:\n",
      "    r = x\n",
      "  else:\n",
      "    r = y\n",
      "  return r\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.jit.script\n",
    "def foo(x, y):\n",
    "    if x.max() > y.max():\n",
    "        r = x\n",
    "    else:\n",
    "        r = y\n",
    "    return r\n",
    "\n",
    "print(type(foo))  # torch.jit.ScriptFunction\n",
    "\n",
    "# See the compiled graph as Python code\n",
    "print(foo.code)\n",
    "\n",
    "# Call the function using the TorchScript interpreter\n",
    "foo(torch.ones(2, 2), torch.ones(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "# Scripting a function using example_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.jit.ScriptFunction'>\n",
      "def test_sum(a: Tensor,\n",
      "    b: Tensor) -> Tensor:\n",
      "  return torch.add(a, b)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ningzhangcaltech/miniconda3/envs/pyscf_isdf/lib/python3.10/site-packages/torch/jit/_script.py:1330: UserWarning: Warning: monkeytype is not installed. Please install https://github.com/Instagram/MonkeyType to enable Profile-Directed Typing in TorchScript. Refer to https://github.com/Instagram/MonkeyType/blob/master/README.rst to install MonkeyType. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(120)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def test_sum(a, b):\n",
    "    return a + b\n",
    "\n",
    "# Annotate the arguments to be int\n",
    "scripted_fn = torch.jit.script(test_sum, example_inputs=[(3, 4)])\n",
    "\n",
    "print(type(scripted_fn))  # torch.jit.ScriptFunction\n",
    "\n",
    "# See the compiled graph as Python code\n",
    "print(scripted_fn.code)\n",
    "\n",
    "# Call the function using the TorchScript interpreter\n",
    "a = torch.as_tensor(20)\n",
    "b = torch.as_tensor(100)\n",
    "scripted_fn(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example (scripting a simple module with a Parameter):\n",
    "\n",
    "Scripting an nn.Module by default will compile the forward method and recursively compile any methods, submodules, and functions called by forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input: Tensor) -> Tensor:\n",
      "  weight = self.weight\n",
      "  output = torch.mv(weight, input)\n",
      "  linear = self.linear\n",
      "  return (linear).forward(output, )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self, N, M):\n",
    "        super().__init__()\n",
    "        # This parameter will be copied to the new ScriptModule\n",
    "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
    "\n",
    "        # When this submodule is used, it will be compiled\n",
    "        self.linear = torch.nn.Linear(N, M)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.weight.mv(input)\n",
    "\n",
    "        # This calls the `forward` method of the `nn.Linear` module, which will\n",
    "        # cause the `self.linear` submodule to be compiled to a `ScriptModule` here\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "scripted_module = torch.jit.script(MyModule(2, 3))\n",
    "\n",
    "print(scripted_module.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example (scripting a module with traced submodules):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input: Tensor) -> Tensor:\n",
      "  conv1 = self.conv1\n",
      "  input0 = __torch__.torch.nn.functional.relu((conv1).forward(input, ), False, )\n",
      "  conv2 = self.conv2\n",
      "  input1 = __torch__.torch.nn.functional.relu((conv2).forward(input0, ), False, )\n",
      "  return input1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # torch.jit.trace produces a ScriptModule's conv1 and conv2\n",
    "        self.conv1 = torch.jit.trace(nn.Conv2d(1, 20, 5), torch.rand(1, 1, 16, 16))\n",
    "        self.conv2 = torch.jit.trace(nn.Conv2d(20, 20, 5), torch.rand(1, 20, 16, 16))\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = F.relu(self.conv1(input))\n",
    "        input = F.relu(self.conv2(input))\n",
    "        return input\n",
    "\n",
    "scripted_module = torch.jit.script(MyModule())\n",
    "\n",
    "print(scripted_module.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example (an exported and ignored method in a module):\n",
    "\n",
    "To compile a method other than forward (and recursively compile anything it calls), add the @torch.jit.export decorator to the method. To opt out of compilation use @torch.jit.ignore or @torch.jit.unused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.7463, 10.6978],\n",
      "        [ 9.3826, 11.3236]])\n",
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/tmp/ipykernel_754881/3153929141.py\u001b[0m(17)\u001b[0;36mpython_only_fn\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     15 \u001b[0;31m        \u001b[0;31m# Python APIs can be used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 17 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "tensor([[ 114.5182,   17.4755],\n",
      "        [-275.7512, -146.5401]])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @torch.jit.export\n",
    "    def some_entry_point(self, input):\n",
    "        return input + 10\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def python_only_fn(self, input):\n",
    "        # This function won't be compiled, so any\n",
    "        # Python APIs can be used\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            self.python_only_fn(input)\n",
    "        return input * 99\n",
    "\n",
    "scripted_module = torch.jit.script(MyModule())\n",
    "print(scripted_module.some_entry_point(torch.randn(2, 2)))\n",
    "print(scripted_module(torch.randn(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example ( Annotating forward of nn.Module using example_inputs):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following examples do not work ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't redefine NamedTuple: __torch__.MyModule",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m pdt_model \u001b[38;5;241m=\u001b[39m TestNNModule()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Runs the pdt_model in eager model with the inputs provided and annotates the arguments of forward\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m scripted_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscript\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mpdt_model\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Run the scripted_model with actual inputs\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(scripted_model([\u001b[38;5;241m20\u001b[39m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/pyscf_isdf/lib/python3.10/site-packages/torch/jit/_script.py:1338\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m   1337\u001b[0m     obj \u001b[38;5;241m=\u001b[39m call_prepare_scriptable_func(obj)\n\u001b[0;32m-> 1338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_recursive\u001b[38;5;241m.\u001b[39mcreate_script_module(\n\u001b[1;32m   1339\u001b[0m         obj, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_recursive\u001b[38;5;241m.\u001b[39minfer_methods_to_compile\n\u001b[1;32m   1340\u001b[0m     )\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1342\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m__prepare_scriptable__() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__prepare_scriptable__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m obj  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyscf_isdf/lib/python3.10/site-packages/torch/jit/_recursive.py:558\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    557\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[38;5;241m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyscf_isdf/lib/python3.10/site-packages/torch/jit/_recursive.py:635\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n\u001b[0;32m--> 635\u001b[0m     \u001b[43mcreate_methods_and_properties_from_stubs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_stubs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_stubs\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;66;03m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;66;03m# If done before, hooks can overshadow methods that aren't exported.\u001b[39;00m\n\u001b[1;32m    640\u001b[0m     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyscf_isdf/lib/python3.10/site-packages/torch/jit/_recursive.py:467\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    464\u001b[0m property_defs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdef_ \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[1;32m    465\u001b[0m property_rcbs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mresolution_callback \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[0;32m--> 467\u001b[0m \u001b[43mconcrete_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_methods_and_properties\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproperty_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defaults\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyscf_isdf/lib/python3.10/site-packages/torch/jit/annotations.py:506\u001b[0m, in \u001b[0;36mtry_ann_to_type\u001b[0;34m(ann, loc, rcb)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rcb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     rcb \u001b[38;5;241m=\u001b[39m _fake_rcb\n\u001b[0;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_type_from_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't redefine NamedTuple: __torch__.MyModule"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "#import torch.nn as nn\n",
    "from typing import NamedTuple, List\n",
    "\n",
    "class MyModule(NamedTuple):\n",
    "    result: List[int]\n",
    "\n",
    "class TestNNModule(torch.nn.Module):\n",
    "    def forward(self, a) -> MyModule:\n",
    "        result = MyModule(result=a).result\n",
    "        return result\n",
    "\n",
    "pdt_model = TestNNModule()\n",
    "\n",
    "# Runs the pdt_model in eager model with the inputs provided and annotates the arguments of forward\n",
    "scripted_model = torch.jit.script(pdt_model, example_inputs={pdt_model: [([10, 20, ], ), ], })\n",
    "\n",
    "# Run the scripted_model with actual inputs\n",
    "print(scripted_model([20]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyscf_isdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
